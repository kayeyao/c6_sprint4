{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBKh82-q6Eom"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmRfsBOe6TVo"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyJB2DbG6gAH",
        "outputId": "31af1553-47cd-495c-8425-03766496c957"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180944 sha256=050f0b63a298a779d4f7b31f8925bec04e1b571134a94b6db2eb1890ccaa2437\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0lyg2qy4/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "786p2lLu6lit",
        "outputId": "43f8a656-ac85-456a-9174-ca600816488a"
      },
      "source": [
        "### tokenization\r\n",
        "# u->unicode\r\n",
        "doc = nlp(u'I am flying to Manila')\r\n",
        "print([w.text for w in doc])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'flying', 'to', 'Manila']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDftXWlt68L1",
        "outputId": "cdcce415-58a9-4a51-aadc-925d0f9378c4"
      },
      "source": [
        "### lemmatization\r\n",
        "\r\n",
        "doc = nlp(u'this product integrates both libraries for downloading and applying patches')\r\n",
        "for token in doc:\r\n",
        "    print(token.text, token.lemma_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this this\n",
            "product product\n",
            "integrates integrate\n",
            "both both\n",
            "libraries library\n",
            "for for\n",
            "downloading download\n",
            "and and\n",
            "applying apply\n",
            "patches patch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW8ILsh_68JX",
        "outputId": "c97bd91b-2b6f-48c2-fdc9-4375fd7ba2f2"
      },
      "source": [
        "### Part of speech tagging\r\n",
        "\r\n",
        "doc = nlp(u'I have flown to Cebu. Now I am flying to Manila.')\r\n",
        "for token in doc:\r\n",
        "    print(token.text, token.pos_, token.tag_)\r\n",
        "    \r\n",
        "# token.tag - more detailed pos"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON PRP\n",
            "have AUX VBP\n",
            "flown VERB VBN\n",
            "to ADP IN\n",
            "Cebu PROPN NNP\n",
            ". PUNCT .\n",
            "Now ADV RB\n",
            "I PRON PRP\n",
            "am AUX VBP\n",
            "flying VERB VBG\n",
            "to ADP IN\n",
            "Manila PROPN NNP\n",
            ". PUNCT .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nPj_QeU-8dmI",
        "outputId": "e0039354-722a-40a9-9acc-1a8dc0450b89"
      },
      "source": [
        "spacy.explain('PRP')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pronoun, personal'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKAKBpl68Go",
        "outputId": "d58aba4b-ab6f-4f93-e142-e8ca23d39448"
      },
      "source": [
        "doc = nlp(u'I have flown to Cebu. Now I am flying to Manila.')\r\n",
        "for sent in doc.sents:\r\n",
        "    print([sent[i] for i in range(len(sent))])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I, have, flown, to, Cebu, .]\n",
            "[Now, I, am, flying, to, Manila, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK0RQFb3679B",
        "outputId": "9fdfd38b-3430-4ab3-a164-b488cfd52cd6"
      },
      "source": [
        "doc = nlp(u'The Golden Gate Bridge is an iconic landmark in San Francisco.')\r\n",
        "[doc[i] for i in range(len(doc))]\r\n",
        "\r\n",
        "## retokenize\r\n",
        "\r\n",
        "# Golden Gate Bridge\r\n",
        "with doc.retokenize() as retokenizer:\r\n",
        "    retokenizer.merge(doc[1:4])\r\n",
        "    \r\n",
        "# SF\r\n",
        "with doc.retokenize() as retokenizer:\r\n",
        "    retokenizer.merge(doc[7:9])\r\n",
        "    \r\n",
        "for token in doc:\r\n",
        "    print(token.text, token.lemma_, token.pos_)    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The the DET\n",
            "Golden Gate Bridge Golden Gate Bridge PROPN\n",
            "is be AUX\n",
            "an an DET\n",
            "iconic iconic ADJ\n",
            "landmark landmark NOUN\n",
            "in in ADP\n",
            "San Francisco San Francisco PROPN\n",
            ". . PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jul_mGd266wx",
        "outputId": "acfdd72c-988b-46d5-c092-d94a261e16bf"
      },
      "source": [
        "### syntactic parsing\r\n",
        "# dep - dependency\r\n",
        "\r\n",
        "doc = nlp(u'I want a green apple.')\r\n",
        "for token in doc:\r\n",
        "    print(token.text, token.pos_, token.dep_, spacy.explain(token.dep_))\r\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON nsubj nominal subject\n",
            "want VERB ROOT None\n",
            "a DET det determiner\n",
            "green ADJ amod adjectival modifier\n",
            "apple NOUN dobj direct object\n",
            ". PUNCT punct punctuation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioGVSut167W8",
        "outputId": "008245dd-de67-4607-cf6b-19d7874b1510"
      },
      "source": [
        "from spacy import displacy\r\n",
        "displacy.serve(doc, style = 'dep')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "X566WIYa67cF",
        "outputId": "0cd1dfdd-2414-408f-c331-54096240554f"
      },
      "source": [
        "##Get $ amount using spacy\r\n",
        "\r\n",
        "doc = nlp(u'The firm earned $1.5 million in 2017, in comparison with $1.2 million in 2016.')\r\n",
        "phrase=''\r\n",
        "\r\n",
        "for token in doc:\r\n",
        "    if token.tag_ = '$':\r\n",
        "        phrase = token.text\r\n",
        "        i = token.i + 1\r\n",
        "        while doc[i].tag_ = 'CD':\r\n",
        "            phrase += doc[i].text + ' '\r\n",
        "            i += 1\r\n",
        "        phrase = phrase[:-1]\r\n",
        "        print(phrase)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-bde82856dd24>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if token.tag_ = '$':\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Sl5deR7MUa",
        "outputId": "dd3f1444-712c-4f26-9f5c-90a520bd3a9d"
      },
      "source": [
        "# Get $amount using regex\r\n",
        "import re\r\n",
        "\r\n",
        "pattern = '\\$.*million'\r\n",
        "test_string = 'The firm earned $1.5 million in 2017.'\r\n",
        "result = re.findall(pattern, test_string)\r\n",
        "print(result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['$1.5 million']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2nxTnUz7MSR",
        "outputId": "9063956b-c988-4f5b-c8ad-a930a73538b3"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "pattern = '\\$.+?million'\r\n",
        "test_string = 'The firm earned $1.5 million in 2017, in comparison with $1.2 million in 2016.'\r\n",
        "result = re.findall(pattern, test_string)\r\n",
        "print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['$1.5 million', '$1.2 million']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "IeZHwVNn7MQX",
        "outputId": "b71b0749-c960-44ee-df90-e744d6803e5c"
      },
      "source": [
        "### entity recognition\r\n",
        "#NORP - nationalities or religiouis or political group\r\n",
        "\r\n",
        "from IPython.core.display import display, HTML\r\n",
        "\r\n",
        "doc = nlp(u'I want a Greek pizza.')\r\n",
        "\r\n",
        "from spacy import displacy\r\n",
        "html = displacy.render(doc, style = 'ent', page = True)\r\n",
        "\r\n",
        "display(HTML(html))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I want a \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Greek\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " pizza.</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "CyvSlglM7MNq",
        "outputId": "82799689-d15a-4c05-ac47-7ed56ecaf536"
      },
      "source": [
        "from IPython.core.display import display, HTML\r\n",
        "\r\n",
        "doc = nlp(u'I want to fly to Manila.')\r\n",
        "\r\n",
        "from spacy import displacy\r\n",
        "html = displacy.render(doc, style = 'ent', page = True)\r\n",
        "\r\n",
        "display(HTML(html))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I want to fly to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Manila\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox2relaz7MLY",
        "outputId": "e47e91bb-e212-4529-834d-02a5ff78a2a6"
      },
      "source": [
        "##similarity\r\n",
        "\r\n",
        "doc = nlp(u'I want a green apple.')\r\n",
        "doc.similarity(doc[2:5])\r\n",
        "\r\n",
        "doc.similarity(doc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKcRbTjD7MIp",
        "outputId": "55944983-2af9-4c9d-a466-835670f6906a"
      },
      "source": [
        "nlp('apple').similarity(nlp('banana'))\r\n",
        "nlp('king').similarity(nlp('queen'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6853425177985294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTl5T1N07MGP",
        "outputId": "7ecda76d-986d-4a92-8c6b-c977ac7aefa9"
      },
      "source": [
        "#embedding\r\n",
        "nlp('banana').vector"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.5882427 , -4.622345  ,  0.835494  , -1.5251803 ,  2.5824933 ,\n",
              "        2.242254  ,  1.1259234 , -0.21041167,  1.8154271 ,  2.7201712 ,\n",
              "        3.8814943 ,  0.16758633,  0.26242155, -1.7026334 ,  1.5412636 ,\n",
              "       -0.393943  , -2.876206  ,  3.2735553 ,  0.23344952,  0.18415219,\n",
              "        0.43752107,  2.1485398 ,  0.4193222 , -2.0388541 ,  0.65415883,\n",
              "       -1.294862  ,  2.4144628 , -2.745386  ,  2.1168573 , -1.8451903 ,\n",
              "        2.027801  , -1.6202624 ,  0.5726354 ,  0.34060296,  0.8692036 ,\n",
              "       -3.8980675 ,  4.6901174 ,  2.1622126 , -1.4661814 ,  0.23460823,\n",
              "        4.3306155 ,  1.6257911 ,  0.12003034, -5.4100738 ,  0.7476239 ,\n",
              "        1.5680416 , -0.84663755,  0.17939603,  0.13341138,  2.232483  ,\n",
              "       -2.099672  , -3.020019  , -0.95659536, -0.01012713, -2.1324272 ,\n",
              "       -0.92933816,  1.2745494 ,  1.927857  , -0.4788074 ,  1.7574201 ,\n",
              "        0.5604429 , -1.4527423 , -2.4652877 ,  2.0573397 , -0.4817862 ,\n",
              "       -1.7056906 ,  2.9862657 , -3.3478055 , -0.13413234,  1.8573143 ,\n",
              "       -4.185879  , -0.08914623,  1.5831141 ,  3.9158773 , -1.3643161 ,\n",
              "        1.4667569 , -0.6691793 , -2.530055  , -2.511684  ,  1.1735829 ,\n",
              "       -0.7318352 , -0.30954093, -3.1022692 , -2.087207  ,  0.1644716 ,\n",
              "        3.8358617 , -0.2781018 , -1.8085173 , -2.180633  , -3.119171  ,\n",
              "        0.8056311 ,  0.9854484 , -1.6096117 ,  2.5635114 ,  1.6108781 ,\n",
              "        0.9410608 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQeVvFBY7MD4"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRucI0xB7L7p"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}